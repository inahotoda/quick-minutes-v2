import { NextRequest, NextResponse } from "next/server";
import { generateEverythingStream, GEMINI_MODEL, fileManager, waitForFileActive, SpeakerInfo } from "@/lib/gemini";
import { transcribeWithSpeakerDiarization, TranscriptionResult } from "@/lib/speech-to-text";
import { MeetingMode } from "@/types";
import { promises as fs } from "fs";
import path from "path";
import os from "os";

import { findFileByName, getFileContent } from "@/lib/drive";

const PROMPTS_FILENAME = "prompts-config.json";
const LOCAL_PROMPTS_FILE = path.join(process.cwd(), "prompts-config.json");
const CONFIG_FOLDER_ID = "1gl7woInG6oJ5UuaRI54h_TTRbGatzWMY";

async function loadCustomPrompts() {
    try {
        // 1. Google Driveã‹ã‚‰æ¤œç´¢
        const file = await findFileByName(PROMPTS_FILENAME, CONFIG_FOLDER_ID);
        if (file && file.id) {
            const content = await getFileContent(file.id) as any;
            return typeof content === "string" ? JSON.parse(content) : content;
        }

        // 2. ãªã‘ã‚Œã°ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆåˆæœŸå€¤ï¼‰ã‹ã‚‰èª­ã¿è¾¼ã¿
        const data = await fs.readFile(LOCAL_PROMPTS_FILE, "utf-8");
        return JSON.parse(data);
    } catch {
        return {};
    }
}

async function saveBase64ToTmp(base64: string, filename: string): Promise<string> {
    const buffer = Buffer.from(base64, "base64");
    const tmpPath = path.join(os.tmpdir(), `${Date.now()}-${filename.replace(/[^a-zA-Z0-9.-]/g, "_")}`);
    await fs.writeFile(tmpPath, buffer);
    return tmpPath;
}

export async function POST(request: NextRequest) {
    const encoder = new TextEncoder();

    try {
        const body = await request.json();
        const { mode, transcript, audioData, uploadedFiles, date, useSpeakerDiarization = true } = body;
        console.log("ğŸš€ [API] Start processing generation request", {
            mode,
            hasAudio: !!audioData,
            filesCount: uploadedFiles?.length,
            useSpeakerDiarization
        });

        console.log("ğŸš€ [API] Loading custom prompts...");
        const customPrompts = await loadCustomPrompts();
        console.log("ğŸš€ [API] Custom prompts loaded");

        const geminiFiles: string[] = [];
        if (audioData?.fileId) geminiFiles.push(audioData.fileId);
        if (uploadedFiles) uploadedFiles.forEach((f: any) => { if (f.fileId) geminiFiles.push(f.fileId); });

        if (geminiFiles.length > 0) {
            console.log("ğŸš€ [API] Phase 1: Waiting for Gemini files to be ACTIVE...");
            await waitForFileActive(geminiFiles);
            console.log("ğŸš€ [API] Phase 1: Complete");
        }

        // Phase 1.5: Speech-to-Textã§è©±è€…åˆ†é›¢ä»˜ãæ–‡å­—èµ·ã“ã—ï¼ˆéŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
        let speakerInfo: SpeakerInfo | undefined;

        if (audioData?.base64 && useSpeakerDiarization) {
            console.log("ğŸš€ [API] Phase 1.5: Starting Speech-to-Text with speaker diarization...");
            try {
                const audioBuffer = Buffer.from(audioData.base64, "base64");
                const transcriptionResult = await transcribeWithSpeakerDiarization(audioBuffer);

                if (transcriptionResult.formattedTranscript) {
                    speakerInfo = {
                        speakerMapping: transcriptionResult.speakerMapping,
                        formattedTranscript: transcriptionResult.formattedTranscript,
                    };
                    console.log(`ğŸš€ [API] Phase 1.5: Complete. Identified ${Object.keys(transcriptionResult.speakerMapping).length} speakers`);
                    console.log(`ğŸš€ [API] Speakers: ${JSON.stringify(transcriptionResult.speakerMapping)}`);
                }
            } catch (error) {
                console.error("âš ï¸ [API] Speech-to-Text failed, falling back to Gemini-only:", error);
                // Speech-to-TextãŒå¤±æ•—ã—ã¦ã‚‚ã€Geminiã§å‡¦ç†ã‚’ç¶šè¡Œ
            }
        }

        const stream = new ReadableStream({
            async start(controller) {
                console.log("ğŸš€ [API] Phase 2: Starting generation stream...");
                try {
                    const genStream = generateEverythingStream({
                        mode: mode as MeetingMode,
                        transcript,
                        audioData: audioData,
                        uploadedFiles: uploadedFiles,
                        date,
                        customPrompts,
                        speakerInfo,
                    });

                    let chunkCount = 0;
                    for await (const chunk of genStream) {
                        if (chunkCount === 0) {
                            console.log("ğŸš€ [API] SUCCESS: Received FIRST chunk from Gemini!");
                        }
                        chunkCount++;
                        controller.enqueue(encoder.encode(chunk));
                    }
                    console.log(`ğŸš€ [API] Generation finished. Total chunks: ${chunkCount}`);
                    controller.close();
                } catch (error) {
                    console.error("âŒ [API] Stream generation error:", error);
                    controller.error(error);
                }
            },
        });

        return new Response(stream, {
            headers: {
                "Content-Type": "text/plain; charset=utf-8",
                "Cache-Control": "no-cache",
                "X-Model-Version": encodeURIComponent(GEMINI_MODEL),
            },
        });
    } catch (error) {
        console.error("POST /api/generate: Generate error:", error);
        return NextResponse.json({ error: error instanceof Error ? error.message : "ç”Ÿæˆã‚¨ãƒ©ãƒ¼" }, { status: 500 });
    }
}
